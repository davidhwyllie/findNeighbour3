import networkx as nx
import datetime
import unittest
import logging
import pandas as pd

class snv_clustering():
    """ maintains clusters of samples """
    def __init__(self,
                 saved_result=None,
                 snv_threshold=None,
                 mixed_sample_management='ignore',
                 store_history=True):
        """ makes clusters of samples such that all samples can be
        reached from each other with <= snv_threshold SNV
        
        saved_result is either:
        - None
        - a dictionary, generated by .to_dict(), containing a previously stored graph and other parameters used
        to restore a snv_clustering object.
        
        If a saved_result is supplied, all the other parameters are is ignored.
        
        In a first run situation (i.e. creating a new snv_clustering object), snv 
        and mixed_sample_management are set.  They cannot be modified subsequently.
        
        snv - the clustering threshold; samples are joined if <= snv from each other.

        mixed_sample_management: dictates how mixed samples are dealt with
        'ignore': the clustering ignores the 'is_mixed' property.  This is the behaviour of standard 'snp address' and related approaches.
       
        'exclude':  the clusters do not include guids with 'is_mixed'=True properties.
                    mixed samples exist only as single-element clusters.
        'include':  samples are included in clusters to which they are
                    similar.
                    One guid can belong to more than one cluster.
                    
             
        Note that in all the below documentation, 'guid' refers to a node identified by a guid,
        and 'guids' to multiple such nodes.
        
        store_history: whether to store a history if properties change.
        """
    
        # if provided, reload the graph.
        self.store_history = store_history
        if isinstance(saved_result, dict):
            logging.info("Reloading saved clustering result")

            self.G =  nx.json_graph.node_link_graph(saved_result['G'])
            self.change_id = saved_result['change_id']
            self.cluster_id = saved_result['cluster_id']
            self.mixed_sample_management = saved_result['mixed_sample_management']
            self.snv_threshold = saved_result['snv_threshold']
            
        elif saved_result is None:
            logging.info("Setting up a new in-ram snv_clustering object")
            if snv_threshold is None:
                raise ValueError("Asked to new clustering object but snv_threshold is none.  This is not allowed.")
            self.G= nx.Graph()
            self.change_id =0
            self.cluster_id = 0
            self.mixed_sample_management = mixed_sample_management
            self.snv_threshold = snv_threshold
            if not mixed_sample_management in ['ignore','include','exclude']:
                raise ValueError("On startup, mixed_sample_management must be one of all, include, exclude")
        else:
            raise TypeError("Do not know how to reload a clustering result from an object of class {0}; a dict is expected".format(saved_result))
    def raise_error(self,token):
        """ raises a ZeroDivisionError, with token as the message.
        useful for unit tests of error logging """
        raise ZeroDivisionError(token)
    def to_dict(self):
        """ converts snv_clustering object to a dictionary.  """
        retVal = {}
        retVal['G']= nx.json_graph.node_link_data(self.G)
        retVal['change_id']=self.change_id 
        retVal['cluster_id']=self.cluster_id
        retVal['mixed_sample_management'] = self.mixed_sample_management
        retVal['snv_threshold'] = self.snv_threshold
        return retVal
    def _new_cluster_id(self):
        """ provides unused integer numbers for assignation to new clusters.
        The numbers do not automatically increase; if integer cluster_ids exist
        which are not used, they may be reused.  For example, if
        integers 1,3,4,5 are used, 2 may be assigned.
        
        note that _new_cluster_id() is new relative to the graph.  If you call _new_cluster_id() repeatedly,
        it will return the same number until the _new_cluster_id() is actually inserted.
        """
        
        new_cluster_id = None
        existing_cluster_ids = set()
        for guid, this_cluster_id_list in self.G.nodes.data('cluster_id'):
            if this_cluster_id_list is not None:
                if not isinstance(this_cluster_id_list, list):
                    raise TypeError("Expected a cluster_id list for {0}, but got {1}".format(guid, this_cluster_id_list))
                for this_cluster_id in this_cluster_id_list:
                    existing_cluster_ids.add(this_cluster_id)
        if len(existing_cluster_ids) == 0:
            return 1        # the first cluster_id allocated.
        else:
            for i in range(1, 1+max(existing_cluster_ids)):
                if not i in existing_cluster_ids:
                    return i
            return 1+ max(existing_cluster_ids)       
    def is_mixed(self,guid):
        """ determines whether a guid is mixed """
        try:
            if self.G.node[guid]['is_mixed']==True:
                return True
        except KeyError:
            # there is no is_mixed attribute
            pass
        return False
    def guids(self):
        """ returns a set of all guids in the graph """
        return set(self.G.nodes)  
    def guid2clusters(self,guid):
        """ returns the cluster(s) a guid belongs to """
        if not guid in self.G.nodes:
            return None     # no guid
        try:
            return self.G.node[guid]['cluster_id']
        except KeyError:
            raise KeyError("Was asked to return the cluster_id of {0}; the guid exists, but does nto have a 'cluster_id' key (likely software error) {1}".format(guid, self.G.node.data()))
    def clusters2guid(self):
        """ returns a cluster -> guid mapping """
        retVal = {}
        for guid in sorted(self.G.nodes):
            try:
                for cluster_id in self.G.node[guid]['cluster_id']:
                    if not cluster_id in retVal.keys():
                        retVal[cluster_id] = []  
                    retVal[cluster_id].append(guid)
            except KeyError:
                # no cluster_id
                pass
        return retVal        
    def clusters2guidmeta(self, after_change_id=None):
        """ returns a cluster -> guid mapping """
        retVal = []
        for guid in sorted(self.G.nodes):
            for cluster_id in self.G.node[guid]['cluster_id']:
                change_id = self.G.node[guid]['change_id']
                is_mixed = self.is_mixed(guid)
                if (after_change_id is None) or (change_id > after_change_id):
                    retVal.append({'guid':guid, 'cluster_id':cluster_id,'change_id':change_id, 'is_mixed':is_mixed})
        return retVal  
    def guids_linked_to(self,guids_of_interest):
        """ identifies all guids in the
        same cluster(s) as guids_of_interest.
                
        The background is that when updating the graph when samples
        are detected to be mixed, then it is necessary to supply
        *all* the edges between the samples which can be reached from the mixed_guids. 
        
        The clustering object does not store all the edges, because of size concerns,
        but without all the edges it cannot accurately repartition the cluster
        when mixed sample recognition means that the cluster needs to be rebuilt.
        
        inputs:
            guids_of_interest: a list of guids which are recognised as mixed.
        
        outputs:
            a list of linked guids
        """
   
        linked_guids = set()
        cluster_ids_of_interest = set()
        for guid in guids_of_interest:
            for cluster_id in self.guid2clusters(guid):
                cluster_ids_of_interest.add(cluster_id)
        for guid in self.guids():
            if len(set(self.guid2clusters(guid)) & cluster_ids_of_interest)>0:
                linked_guids.add(guid)
        return(list(linked_guids))           
    def _change_guid_attribute(self,guid,attribute,value):
        """ updates a guid's attribute with a new value.
        Keeps a track of what changed, and when.
        
        If the function is instructed to change a value, but
        it doesn't need to be changed (i.e. the current value is equal to value)
        then no update is made."""
   
        # get a copy of the history of the object

        if not 'history' in self.G.node[guid].keys():
            h = [(self.change_id,"created change history post creation")]
        else:      
            h = self.G.node[guid]['history']        # read existing history
        if not attribute in self.G.node[guid].keys():
            # doesn't exist
            h.append((self.change_id, "created {0} as {1}".format(attribute,value)))
            self.G.node[guid][attribute]=value
            self.G.node[guid]['history']=h
            self.G.node[guid]['change_id']=self.change_id 
            return 
        else:
            existing_value = self.G.node[guid][attribute]
            is_same = False
            if isinstance(existing_value, list):
                # we don't enforce order of lists
                if set(existing_value)==set(value):
                    is_same = True
            else:
                if existing_value == value:
                    is_same==True
            
            if not is_same:

                self.G.node[guid][attribute]=value
                self.G.node[guid]['change_id']=self.change_id
                if self.store_history:
                    h.append((self.change_id, {"{0}":{"from":existing_value,"to":value}}))
                    self.G.node[guid]['history']=h
            else:
                pass
    def _minimise_edges(self, in_cluster_guids):
        """ rearrange the graph, ensuring that
         all the guids in in_cluster_guids are still reachable from each other,
         while also ensuring that the number of edges is minimised.
         This strategy keeps down the number of edges which needs to be stored - for n
         similar nodes we only have to store (n-1) edges, rather than n^2.
         
         The only exception is that any edges involving mixed samples are left untouched.
         """
         
        new_E = []
        existing_E = []

        connected_guids = sorted(list(in_cluster_guids))  # sort to make function deterministic 
        # make edges which link the nodes in the component, stringwise
        for i in range(len(connected_guids)-1):
            new_E.append((connected_guids[i], connected_guids[i+1]))
            for adjacent_node in list(self.G.adj[connected_guids[i]]):
                if not self.is_mixed(connected_guids[i]) and not self.is_mixed(adjacent_node):
                    existing_E.append([connected_guids[i], adjacent_node])

        self.G.remove_edges_from(existing_E)
        self.G.add_edges_from(new_E)
    def _update_clusterid_to_largest_cluster(self, in_cluster_guids):
        """ set the cluster_ids of in_cluster_guids to that of
        the largest existing group of samples within in_cluster_guids
        for example, if we had five guids 1,2,3,4,5
        and guids 1,2, and 3 had a cluster_id of 1, while 4,5 had a cluster_id of 2,
        then all samples would be assigned a cluster_id of 1.
        
        If two clusters are of the same size, picks the smaller one to update with.
        
        If some guids are identified as possibly mixed (self.is_mixed(guid) == True),
        and so can legitimately belong to > 1 cluster, this function will operate  correctly.
        
        However, in this case, it will only analyse guids which are not mixed when
        determining the cluster_ids to update.  Because of this,
        it's essential to call _update_cluster_id_to_largest_cluster BEFORE
        setting is_mixed==True.  The set_mixture_status() function does this automatically.
        
        This function is one way of making the cluster numbers assigned relatively stable when
        clusters merge.
        """
            
        guid2cl = nx.get_node_attributes(self.G,'cluster_id')        # links guid to cluster id for all nodes.

        cl2n = {}           # a dictionary linking cluster to number of guids within the cluster,
                            # as currently recorded in the graph.
        
        # compute the number of guids per cluster;
        for guid in in_cluster_guids:     # guid2cl has all of them;
            for this_cluster_id in guid2cl[guid]:
                if not this_cluster_id in cl2n.keys():
                    cl2n[this_cluster_id]=0
                cl2n[this_cluster_id]+=1
       
        # find the cluster_id with the largest number of clusters;

        largest_cluster_size = max(cl2n.values())
        for new_cluster_id in sorted(cl2n.keys()):      # enforces deterministic behaviour
            if cl2n[new_cluster_id]== largest_cluster_size:
                break
        
        # do the update of the cluster identifiers
        # find the existing cluster designations, and are
        # not the new cluster_id.  These are the ones we're going to update.
        to_update = set(cl2n.keys()) - set([new_cluster_id])

        # update the cluster designations                    
        for guid in in_cluster_guids:
            this_guid2cl = guid2cl[guid]        # get the current cluster
            made_update = False
            for i in range(len(this_guid2cl)):
                if this_guid2cl[i] in to_update:
                    this_guid2cl[i] = new_cluster_id
                    made_update = True
            if made_update:
                this_guid2cl = set(this_guid2cl)      # ensure unique elements
                self._change_guid_attribute(guid, 'cluster_id', sorted(list(this_guid2cl)))        ## keep deterministic; use custom function tracking history
    def add_sample(self, starting_guid, neighbours=[]):
        """ adds a sample, guid, linked to neighbours.
        - guid should be a string
        - neighbours should be a list
        - ignores mixture status 
        """
        
        # if starting_guid exists in the network, we do not re-add it.
        if starting_guid in self.G.nodes:
            return
        
        # a counter used to identify the order of changes
        self.change_id +=1

        # create a list of guid - neighbour links,
        # suitable for importing into networkx,
        # from the neighbours provided.  
        E = []
        clids = set()
        for item in neighbours:
            # as long as it is not to a mixed sample, we add this link.
            if not self.is_mixed(item):
                E.append([starting_guid,item])
                for cluster_id in self.guid2clusters(item):
                    clids.add(cluster_id)
                    
        # if there's no cluster_ids linked
        if len(clids)==0:
            clid = self._new_cluster_id()
        elif len(clids)>0:     # expected result
            clid = clids.pop()

        self.G.add_node(starting_guid, **{'change_id':self.change_id, 'cluster_id':[clid], 'history':[(self.change_id, 'added')]})      # in it's own, new cluster.
        self.G.add_edges_from(E)
      
        # find all guids in clids.  This will include any associated mixed samples.
        in_cluster_guids = set([starting_guid])
        lookup = self.clusters2guid()
        for cluster_id in clids:
            for guid in lookup[cluster_id]:
                in_cluster_guids.add(guid)
  
        # relabel clusters post addition
        self._update_clusterid_to_largest_cluster(in_cluster_guids)
        
        # minimise the number of edges, to keep the graph small
        # but everything within each cluster connected.
        self._minimise_edges(in_cluster_guids)
    def connected_components(self):
        """ returns all clusters, including those of size 1, within the graph """
        
        all_guids = self.guids()
        covered_guids = set()
        
        for cluster_components  in nx.connected_components(self.G):
            for guid in cluster_components:
                covered_guids.add(guid)
            yield cluster_components
            
            not_covered = all_guids - covered_guids
            for item in not_covered:
                yield set([item])
    def set_mixture_status(self, guid2similar_guids, change_guids):
        """ marks a set of guids as being mixed

        When updating a cluster to indicate that a sample's mixture status
        has changed, it is necessary to supply *all* the edges between the samples
        to which the mixed_guids are related.  The guids_linked_to()
        function will provide this list.  This is because the clustering object does
        not store all the edges, but without all the edges it cannot accurately
        repartition the cluster when mixed sample recognition means that the cluster
        needs to be rebuilt.
        
        inputs:
            guid2similar_guids : a dictionary of guids -> linked guids less than cutoff
            change_guids: a dictionary of guids -> either True (set mixed) or False (set not mixed)
        
        """

        # sanity checks.
        # check what edge data is needed.
        required_guid2edge_guids = set(self.guids_linked_to(list(change_guids.keys())))
        
        # do we have the required edge data?
        if not required_guid2edge_guids - set(guid2similar_guids.keys()) == set():
            raise KeyError("Asked to set mixture status on {0}.  This requires edge data for {1} however edge data for {2} was supplied.".format(change_guids.keys(), set(required_guid2edge_guids), set(guid2similar_guids.keys())))
    
        # are the change_guids linked to a logical
        for v in change_guids.values():
            if not v in [True, False]:
                raise TypeError("Change_guids must have true/false values not {0} (from : {1})".format(v, change_guids))    
        
        # are the keys of change_guids in required_guid2edge_guids
        for guid in change_guids.keys():
            if not guid in required_guid2edge_guids:
                raise KeyError("Asked to change {0} but neighbour information is not supplied".format(guid))
        # end of validations
        
        
        # check whether the guids to change mixture status on,
        # which are the keys of change_guids, are already set correctly. 
        n_guids = len(change_guids.keys())
        n_mixed = 0
        for guid in change_guids.keys():
            if change_guids[guid] == self.is_mixed(guid):
                n_mixed +=1
        
        # if all are already set, we need do nothing.       
        if n_mixed == len(change_guids.keys()):
            return      # don't have to anything - all already designated as mixed

        # otherwise, we need to make changes.
        # increase the change counter
        self.change_id += 1
          
        # set the relevant samples to mixed
        for guid in change_guids.keys():              
            if not change_guids[guid] == self.is_mixed(guid):
               self._change_guid_attribute(guid, 'is_mixed', change_guids[guid])    ## use custom function tracking history

        if self.mixed_sample_management == 'ignore':
           # then we don't need to change anything
           return
            
        # otherwise .. rebuild clusters, ignoring any mixed samples.
     
        # remove all edges from the guids of interest.
        new_E = []
        existing_E = []
        for guid in required_guid2edge_guids:                      
            for adjacent_node in list(self.G.adj[guid]):
                existing_E.append([guid, adjacent_node])
        self.G.remove_edges_from(existing_E)
    
        # make all links between mixed guids and existing guids, but
        # do not make links involving mixed samples.
        for guid in required_guid2edge_guids:
            neighbours = guid2similar_guids[guid]
            for neighbour in neighbours:
                neither_mixed = (self.is_mixed(guid)==False and self.is_mixed(neighbour)==False)    
                if neither_mixed==True:    # only if the are both not mixed
                     new_E.append((guid,neighbour))

        self.G.add_edges_from(new_E)
            
        # define the cluster(s) which have been generated by this operation
        # note that mixed samples have not yet been added to these.
        n_clusters_found = 0
        for cluster_content in self.connected_components():
            # note any clusters which contain any guids of interest.
            if len(cluster_content.intersection(required_guid2edge_guids))>0:
                n_clusters_found +=1
                # cluster_content is a new cluster.  the largest clusters are delivered first.
                if n_clusters_found == 1:
                    # cluster_content gets named as the old cluster name.
                    # no change is needed
                    pass
                else:
                    new_cluster_id = self._new_cluster_id()
                    for guid in cluster_content:
                        self._change_guid_attribute(guid, 'cluster_id', [new_cluster_id])
  
        #  if include, link guid to any similar clusters.                                            
        if self.mixed_sample_management == 'include':
              for guid in change_guids.keys():
                if self.is_mixed(guid):
                    # identify any clusters which guids is linked to
                    linked_to = set(self.guid2clusters(guid))
                    for linked_guid in guid2similar_guids[guid]:
                        cluster_ids = self.guid2clusters(linked_guid)     
                       
                        for cluster_id in cluster_ids:
                            linked_to.add(cluster_id)
                           
                    # if we haven't found any linked clusters, then we do nothing, as it's in a cluster of its own already.
                   
                    if len(linked_to)==0:
                        pass
                    else:
                        self._change_guid_attribute(guid, 'cluster_id', list(linked_to))
                   
        # simplify the cluster, reducing the number of edges
        self._minimise_edges(required_guid2edge_guids)
        
# unittests
class test_init(unittest.TestCase):
    """ tests init method of snv_clustering """
    def runTest(self):
        """ tests init """
        
        # no parameters except SNV threshold
        snvc = snv_clustering(snv_threshold=12)
        
        self.assertEqual(type(snvc.G), nx.classes.graph.Graph)
        self.assertEqual(snvc.change_id, 0)

class test_to_dict(unittest.TestCase):
    """ tests serialisation to dict """
    def runTest(self):
        snvc = snv_clustering(snv_threshold=12)
        snvc.G.add_node('a', is_mixed=True)
        snvc.G.add_node('b', is_mixed=False)
        d = snvc.to_dict()

        snvc2 = snv_clustering(saved_result=d)
        self.assertTrue(snvc.G, snvc2.G)

class test_is_mixed(unittest.TestCase):
    """ tests _set_mixed function """
    def runTest(self):
        # set up
        snvc = snv_clustering(snv_threshold=12)
        snvc.G.add_node('a', is_mixed=True)
        snvc.G.add_node('b', is_mixed=False)
        
        self.assertFalse(snvc.is_mixed('b'))
        self.assertTrue(snvc.is_mixed('a'))
                   
   
class test_minimise_edges(unittest.TestCase):
    """ tests edge minimisation """
    def runTest(self):
        # set up
        snvc = snv_clustering(snv_threshold=12)
        nodes = ['n1','n2','n3','n4','n5']
        E=[]
        for i in range(len(nodes)):

            for j in range(i):
                E.append((nodes[i],nodes[j]))
            snvc.G.add_node(nodes[i], cluster_id=[1])
        snvc.G.add_edges_from(E)
        
        neighbours_pre = 0
        for node in snvc.G:
            neighbours_pre = neighbours_pre + len(snvc.G.adj[node])
            
        cc_pre = list(nx.connected_components(snvc.G))   
        ## run test
        snvc._minimise_edges(nodes)
        
        # check
        neighbours_post = 0
        for node in snvc.G:
            neighbours_post = neighbours_post + len(snvc.G.adj[node])
            
        cc_post = list(nx.connected_components(snvc.G))   
            
        self.assertEqual(cc_post, cc_pre)      # still all connected
        self.assertTrue(neighbours_post < neighbours_pre)       # edges minimised
        
class test_add_sample_0(unittest.TestCase):
    """ tests allocation of new clusterids """
    def runTest(self):
               
        snvc = snv_clustering(snv_threshold=12)
        
        n1 = snvc._new_cluster_id()
        snvc.G.add_node('n1', cluster_id=[n1])
        n2 = snvc._new_cluster_id()
        snvc.G.add_node('n2', cluster_id=[n2])
        n3 = snvc._new_cluster_id()
        snvc.G.add_node('n3', cluster_id=[n3])
        
        self.assertEqual(n1,1)
        self.assertEqual(n2,2)
        self.assertEqual(n3,3)

        self.assertEqual(snvc._new_cluster_id(),4)
        snvc.G.remove_node('n2')    # number 2 should become available.
        self.assertEqual(snvc._new_cluster_id(),2)

class test_add_sample_0b(unittest.TestCase):
    """ tests that one guid can't be added multiple times."""
    def runTest(self):
               
        snvc = snv_clustering(snv_threshold=12)
        
        snvc.G.add_node('n1')
        snvc.G.add_node('n1', mixed=1)
        
        self.assertEqual(len(snvc.G.nodes),1)

class test_guids_linked_to(unittest.TestCase):
    """ tests guids_linked_to """
    def runTest(self):
        snvc = snv_clustering(snv_threshold=12)

        snvc.G.add_node('n1', cluster_id=[1])
        snvc.G.add_node('n2', cluster_id=[1])
        snvc.G.add_node('n3', cluster_id=[2])
        snvc.G.add_node('n4', cluster_id=[1,3])
 
        res = snvc.guids_linked_to(['n1'])
        self.assertEqual(set(['n1','n2','n4']),set(res)) 

        res = snvc.guids_linked_to(['n3'])
        self.assertEqual(set(['n3']),set(res)) 

        res = snvc.guids_linked_to(['n4'])
        self.assertEqual(set(['n1','n2','n4']),set(res)) 

class test_update_clusterid_1(unittest.TestCase):
    """ tests updating clusterid to that of the largest cluster"""
    def runTest(self):
               
        snvc = snv_clustering(snv_threshold=12)

        snvc.G.add_node('n1', cluster_id=[1])
        snvc.G.add_node('n2', cluster_id=[1])
        snvc.G.add_node('n3', cluster_id=[2])
        snvc.G.add_node('n4', cluster_id=[3])
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        snvc._update_clusterid_to_largest_cluster(['n1','n2','n3'])
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        
        self.assertEqual(cluster_ids, {'n1':[1],'n2':[1],'n3':[1],'n4':[3]})

class test_update_clusterid_2(unittest.TestCase):
    """ tests updating clusterid to that of the largest cluster"""
    def runTest(self):
               
        snvc = snv_clustering(snv_threshold=12)

        snvc.G.add_node('n1', cluster_id=[1])
        snvc.G.add_node('n2', cluster_id=[1])
        snvc.G.add_node('n3', cluster_id=[2])
        snvc.G.add_node('n4', cluster_id=[2])
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        snvc._update_clusterid_to_largest_cluster(['n1','n2','n3','n4'])
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        
        self.assertEqual(cluster_ids, {'n1':[1],'n2':[1],'n3':[1],'n4':[1]})
                
class test_add_sample_2(unittest.TestCase):
    """ tests insertion of new samples, where all form one cluster. """
    def runTest(self):
               
        snvc = snv_clustering(snv_threshold=12)
        
        # add three
        snvc.add_sample('n1')
        self.assertTrue(len(snvc.G.nodes),1)
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        self.assertEqual(cluster_ids, {'n1':[1]})
        snvc.add_sample('n2')
        self.assertTrue(len(snvc.G.nodes),2)
        cluster_ids = nx.get_node_attributes(snvc.G,'cluster_id')
        self.assertEqual(cluster_ids, {'n1':[1],'n2':[2]})
        snvc.add_sample('n3', ['n1','n2'])
        self.assertTrue(len(snvc.G.nodes),3)
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        self.assertEqual(cluster_ids, {'n1':[1],'n2':[1], 'n3':[1]})

class test_add_sample_3(unittest.TestCase):
    """ tests insertion of new samples, where more than one cluster is present.  """
    def runTest(self):
               
        snvc = snv_clustering(snv_threshold=12)
        
        # add three
        snvc.add_sample('n1')
        self.assertTrue(len(snvc.G.nodes),1)
        cluster_ids = nx.get_node_attributes(snvc.G,'cluster_id')
        self.assertEqual(cluster_ids, {'n1':[1]})
        snvc.add_sample('n2')
        self.assertTrue(len(snvc.G.nodes),2)
        cluster_ids = nx.get_node_attributes(snvc.G,'cluster_id')
        self.assertEqual(cluster_ids, {'n1':[1],'n2':[2]})
        snvc.add_sample('n3')
        self.assertTrue(len(snvc.G.nodes),3)
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        self.assertEqual(cluster_ids, {'n1':[1],'n2':[2],'n3':[3]})
        snvc.add_sample('n4'),
        self.assertTrue(len(snvc.G.nodes),4)
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        self.assertEqual(cluster_ids, {'n1':[1],'n2':[2],'n3':[3],'n4':[4]})
        
        snvc.add_sample('n5', ['n1','n2','n3'])
        self.assertTrue(len(snvc.G.nodes),5)
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        self.assertEqual(cluster_ids, {'n1':[1],'n2':[1], 'n3':[1],'n4':[4], 'n5':[1]})
        

class test_add_sample_4(unittest.TestCase):
    """ tests combining clusters, one of which is mixed.  using exclude. """
    def runTest(self):
               
        snvc = snv_clustering(snv_threshold=12, mixed_sample_management='exclude')
        
        # add two clusters
        snvc.add_sample('n1_1')      # cluster 1, member 1

        snvc.add_sample('n2_1')     # cluster 2, members 1-3
        snvc.add_sample('n2_2', ['n2_1'])
        snvc.add_sample('n2_3', ['n2_2'])
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')

        self.assertEqual(cluster_ids, {'n1_1':[1],'n2_1':[2],'n2_2':[2],'n2_3':[2]})
  
        # they are linked by a mixed sample
        snvc.set_mixture_status({'n1_1':[], 'n2_1':['n2_2'],'n2_2':['n2_1','n2_3'], 'n2_3':['n2_2']}, {'n2_2':True})
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')

        self.assertFalse(cluster_ids['n1_1']==cluster_ids['n2_1'])
        self.assertFalse(cluster_ids['n2_1']==cluster_ids['n2_3'])
        self.assertEqual(len(set(cluster_ids['n2_2']+cluster_ids['n2_1']+cluster_ids['n2_3'])),3) # all in different clusters

        snvc.add_sample('n3')
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        self.assertFalse(cluster_ids['n1_1']==cluster_ids['n2_1'])
        self.assertFalse(cluster_ids['n2_1']==cluster_ids['n2_3'])
        self.assertEqual(len(set(cluster_ids['n2_2']+cluster_ids['n2_1']+cluster_ids['n2_3'])),3) # all in different clusters

        snvc.add_sample('n4', ['n1_1','n2_1'])
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        self.assertEqual(cluster_ids['n1_1'], cluster_ids['n2_1'])
        self.assertEqual(cluster_ids['n1_1'], cluster_ids['n4'])
        self.assertFalse(cluster_ids['n2_1']==cluster_ids['n2_3'])
        self.assertEqual(len(set(cluster_ids['n2_2']+cluster_ids['n2_1']+cluster_ids['n2_3'])),3) # all in different clusters

class test_add_sample_5(unittest.TestCase):
    """ tests combining clusters, one of which is mixed.  using ignore (the mixed sample)"""
    def runTest(self):
               
        snvc = snv_clustering(snv_threshold=12, mixed_sample_management='ignore')
        
        # add two clusters
        snvc.add_sample('n1_1')      # cluster 1, member 1

        snvc.add_sample('n2_1')     # cluster 2, members 1-3
        snvc.add_sample('n2_2', ['n2_1'])
        snvc.add_sample('n2_3', ['n2_2'])
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        self.assertEqual(cluster_ids, {'n1_1':[1],'n2_1':[2],'n2_2':[2],'n2_3':[2]})

        #print("PRE:",cluster_ids)
        
        # they are linked by a mixed sample
        snvc.set_mixture_status({'n1_1':[], 'n2_1':['n2_2'],'n2_2':['n2_1','n2_3'], 'n2_3':['n2_2']}, {'n2_2':True})
   
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        #print("POST:",cluster_ids)
        self.assertFalse(cluster_ids['n1_1']==cluster_ids['n2_1'])
        self.assertTrue(cluster_ids['n2_1']==cluster_ids['n2_3'])
        self.assertTrue(cluster_ids['n2_2']==cluster_ids['n2_3'])

        snvc.add_sample('n3')
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        self.assertFalse(cluster_ids['n1_1']==cluster_ids['n2_1'])
        self.assertTrue(cluster_ids['n2_1']==cluster_ids['n2_3'])
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        #print("POST N3:",cluster_ids)
        
        snvc.add_sample('n4', ['n1_1','n2_1'])
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        #print("POST N4:",cluster_ids)
        self.assertFalse(cluster_ids['n1_1']==cluster_ids['n2_1'])
        self.assertFalse(cluster_ids['n1_1']==cluster_ids['n4'])
        self.assertTrue(cluster_ids['n2_1']==cluster_ids['n2_3'])
        self.assertFalse(cluster_ids['n1_1']==cluster_ids['n4'])
        self.assertEqual(len(set(cluster_ids['n2_2']+cluster_ids['n2_1']+cluster_ids['n2_3'])),1) # all in same clusters

class test_add_sample_6(unittest.TestCase):
    """ tests combining clusters, one of which is mixed.  using include (the mixed sample).
    What should happen is that we should get two sets [2_1,2_2], [2-2,2_3]"""
    def runTest(self):
               
        snvc = snv_clustering(snv_threshold=12, mixed_sample_management='include')
        
        # add two clusters
        snvc.add_sample('n1_1')      # cluster 1, member 1

        snvc.add_sample('n2_1')     # cluster 2, members 1-3
        snvc.add_sample('n2_2', ['n2_1'])
        snvc.add_sample('n2_3', ['n2_2'])
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
         
        self.assertEqual(cluster_ids, {'n1_1':[1],'n2_1':[2],'n2_2':[2],'n2_3':[2]})
  
        # they are linked by a mixed sample
        snvc.set_mixture_status({'n1_1':[], 'n2_1':['n2_2'],'n2_2':['n2_1','n2_3'], 'n2_3':['n2_2']}, {'n2_2':True})
   
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        
        self.assertFalse(cluster_ids['n1_1']==cluster_ids['n2_1'])
        self.assertFalse(cluster_ids['n2_1']==cluster_ids['n2_3'])
        self.assertTrue(cluster_ids['n2_3'][0] in cluster_ids['n2_2'])
        self.assertTrue(cluster_ids['n2_1'][0] in cluster_ids['n2_2'])
 

class test_add_sample_7(unittest.TestCase):
    """ tests actions on a cluster with multiple mixed samples. using include (the mixed sample)."""
    def runTest(self):
               
        snvc = snv_clustering(snv_threshold=12, mixed_sample_management='include')
        
        # add two clusters
        snvc.add_sample('n1_1')      # cluster 1, member 1

        snvc.add_sample('n2_1',['n1_1'])     # cluster 2, members 1-3
        snvc.add_sample('n2_2', ['n2_1'])
        snvc.add_sample('n2_3', ['n2_2'])
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
      
        self.assertEqual(cluster_ids, {'n1_1':[1],'n2_1':[1],'n2_2':[1],'n2_3':[1]})
  
        # they are all mixed.
        snvc.set_mixture_status({'n1_1':['n2_1'], 'n2_1':['n1_1','n2_2'],'n2_2':['n2_1','n2_3'], 'n2_3':['n2_2']}, {'n1_1':True,'n2_1':True, 'n2_2':True, 'n2_3':True})
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
        #print(cluster_ids,'POST')
        # how many clusters
        clids = set()
        for clid_list in cluster_ids.values():
            for clid in clid_list:
                clids.add(clid)
        self.assertEqual(len(clids),4)


class test_add_sample_8(unittest.TestCase):
    """ tests combining clusters, one of which is mixed.  using exclude (the mixed sample).
    What should happen is that we should get sets [1-1] [2_1] [2_2] [2_3]"""
    def runTest(self):
               
        snvc = snv_clustering(snv_threshold=12, mixed_sample_management='exclude')
        
        # add two clusters
        snvc.add_sample('n1_1')      # cluster 1, member 1

        snvc.add_sample('n2_1')     # cluster 2, members 1-3
        snvc.add_sample('n2_2', ['n2_1'])
        snvc.add_sample('n2_3', ['n2_2'])
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
         
        self.assertEqual(cluster_ids, {'n1_1':[1],'n2_1':[2],'n2_2':[2],'n2_3':[2]})
  
        # they are linked by a mixed sample
        snvc.set_mixture_status({'n1_1':[], 'n2_1':['n2_2'],'n2_2':['n2_1','n2_3'], 'n2_3':['n2_2']}, {'n2_2':True})
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
       
        self.assertFalse(cluster_ids['n1_1']==cluster_ids['n2_1'])
        self.assertFalse(cluster_ids['n2_1']==cluster_ids['n2_3'])
        self.assertFalse(cluster_ids['n2_3']==cluster_ids['n2_2'])
        self.assertFalse(cluster_ids['n2_1']==cluster_ids['n2_2'])


        snvc.add_sample('n4_1', [])
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')
   
        snvc.set_mixture_status({'n1_1':[], 'n2_1':['n2_2'],'n2_2':['n2_1','n2_3'], 'n2_3':['n2_2'],'n4_1':[]}, {'n2_2':True, 'n4_1':True})
        cluster_ids = nx.get_node_attributes(snvc.G, 'cluster_id')

        
class test_guids(unittest.TestCase):
    """ tests recovery of list of guids """
    def runTest(self):
        snvc = snv_clustering(snv_threshold=12, mixed_sample_management='include')
        self.assertEqual(snvc.guids(),set([]))
            
        # add two samples
        snvc.add_sample('n1')      
        snvc.add_sample('n2')      
        snvc.add_sample('n3')      
        self.assertEqual(snvc.guids(),set(['n1','n2','n3']))

class test_guid2clusters_1(unittest.TestCase):
    """ tests recovery of list of guids """
    def runTest(self):
        snvc = snv_clustering(snv_threshold=12, mixed_sample_management='include')
        self.assertEqual(snvc.guids(),set([]))
            
        # add two samples
        snvc.add_sample('n1')      
        snvc.add_sample('n2')      
        snvc.add_sample('n3')      
        self.assertEqual(snvc.guids(),set(['n1','n2','n3']))

        self.assertEqual(snvc.guid2clusters('n1'), [1])

class test_guid2clusters_2(unittest.TestCase):
    """ tests recovery of list of guids """
    def runTest(self):
        snvc = snv_clustering(snv_threshold=12, mixed_sample_management='include')
        self.assertEqual(snvc.guids(),set([]))
            
        # add two samples
        snvc.add_sample('n1')      
        snvc.add_sample('n2', ['n1'])      
        snvc.add_sample('n3')      
        self.assertEqual(snvc.guids(),set(['n1','n2','n3']))

        self.assertEqual(snvc.guid2clusters('n1'), [1])
        self.assertEqual(snvc.guid2clusters('n3'), [2])
        self.assertEqual(snvc.clusters2guid(), {1:['n1','n2'], 2:['n3']})
        

class test_clusters2guidmeta(unittest.TestCase):
    """ tests recovery of list of guids """
    def runTest(self):
        snvc = snv_clustering(snv_threshold=12, mixed_sample_management='include')
        self.assertEqual(snvc.guids(),set([]))
            
        # add three samples
        snvc.add_sample('n1')      
        snvc.add_sample('n2', ['n1'])      
        snvc.add_sample('n3', ['n2'])      
       
        res = snvc.clusters2guidmeta()
        self.assertEqual(res,
                        [{'guid': 'n1', 'cluster_id': 1, 'change_id': 1, 'is_mixed': False},
                         {'guid': 'n2', 'cluster_id': 1, 'change_id': 2, 'is_mixed': False},
                         {'guid': 'n3', 'cluster_id': 1, 'change_id': 3, 'is_mixed': False}]
                        )

      
        snvc.set_mixture_status({'n1':['n2'], 'n2':['n1','n2','n3'],'n3':['n2']}, {'n2':True})
       
        res3 = snvc.clusters2guidmeta()
        df = pd.DataFrame.from_records(res3)
        #print(df)
        self.assertEqual(len(df.index), 5)
        self.assertEqual(len(df.query('guid=="n2"').index),3)
        self.assertEqual(df['change_id'].tolist(), [1,4,4,4,4])

class test_Raise_error(unittest.TestCase):
    """ tests raise_error"""
    def runTest(self):
        snvc = snv_clustering(snv_threshold=12, mixed_sample_management='include')
                      
        with self.assertRaises(ZeroDivisionError):
            snvc.raise_error("token")
        
class test_set_mixed_1(unittest.TestCase):
    """ tests _set_mixed function """
    def runTest(self):
        # set up
        snvc = snv_clustering(snv_threshold=12)
        snvc.add_sample('c',[])
        self.assertFalse(snvc.is_mixed('c'))
        snvc.set_mixture_status({'c': []},{'c':True})
        self.assertTrue(snvc.is_mixed('c'))

class test_set_mixed_2(unittest.TestCase):
    """ tests set_mixed function """
    def runTest(self):
        # set up
        snvc = snv_clustering(snv_threshold=12)
        snvc.add_sample('c',[])
        self.assertFalse(snvc.is_mixed('c'))
        snvc.set_mixture_status({'c': []},{'c':True})
        self.assertTrue(snvc.is_mixed('c'))
        snvc.set_mixture_status({'c': []},{'c':False})
        self.assertFalse(snvc.is_mixed('c'))
                